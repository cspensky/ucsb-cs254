%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Structured General Purpose Assignment
% LaTeX Template
%
% This template has been downloaded from:
% http://www.latextemplates.com
%
% Original author:
% Ted Pavlic (http://www.tedpavlic.com)
%
% Note:
% The \lipsum[#] commands throughout this template generate dummy text
% to fill the template out. These commands should all be removed when 
% writing assignment content.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{article}

\usepackage{fancyhdr} % Required for custom headers
\usepackage{lastpage} % Required to determine the last page for the footer
\usepackage{extramarks} % Required for headers and footers
\usepackage{graphicx} % Required to insert images
\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template
\usepackage{amsfonts}
\usepackage{subfig}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{forest}
\usepackage{float}
\usepackage{listings}

%----------------------------------------------------------------------------------------
%	NAME AND CLASS SECTION
%----------------------------------------------------------------------------------------

\newcommand{\hmwkTitle}{Assignment\ \#2} % Assignment title
\newcommand{\hmwkDueDate}{Friday,\ June\ 10,\ 2016} % Due date
\newcommand{\hmwkClass}{CS\ 254} % Course/class
\newcommand{\hmwkClassInstructor}{Prof. Tim Sherwood} % Teacher/lecturer
\newcommand{\hmwkAuthorName}{Chad Spensky} % Your name

%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\title{
\vspace{2in}
\textmd{\textbf{\hmwkClass:\ \hmwkTitle}}\\
\normalsize\vspace{0.1in}\small{Due\ on\ \hmwkDueDate}\\
\vspace{0.1in}\large{\textit{\hmwkClassInstructor}}
\vspace{3in}
}

\author{\textbf{\hmwkAuthorName}}
\date{} % Insert date here if you want it to appear below your name

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle
\newpage

\input{macros}

%----------------------------------------------------------------------------------------
%	TABLE OF CONTENTS
%----------------------------------------------------------------------------------------

%\setcounter{tocdepth}{1} % Uncomment this line if you don't want subsections listed in the ToC
%
%\newpage
%\tableofcontents
%\newpage

% To have just one problem per page, simply put a \clearpage after each problem

\section{Streams (3pts)}
Since the stream buffers discussed in the paper work as FIFOs and only compare/pop from the front, we would need at least 2 stream buffers, and they would only be useful for array \textbf{b}, as it is the only one being accesses sequentially.  However, 1001 stream buffers would be able to cache all of the indices for c, and the currently accessed one for b, fully optimizing our accesses.  


\section{Thread Level Parallelism (3pts each)}

\subsection{F}
Thus, the IPC for any one thread is simply the number of instructions divided by the number of cycles taken for the loop. 
More precisely,
\begin{equation*}
IPC = \frac{7~ins}{(.3^2*2+2*(.3*.7)*2+.7^2*20) +5~cycles} \approx .44~ins/cycle
\end{equation*}

However, all of the threads must wait for the longest running thread.  Thus we must look at the probability that all threads have no cache misses, at least on thread having a single cache miss, or at least one thread missing both times.
\begin{equation*}
IPC = \frac{16*7~ins}{16*[2*.3^{2*16}+11*(.3*.7)^{16}*2+20*(1-(.3^{2*16} + 2*(.3*.7)^{16})) + 5]~cycles} \approx 0.28~ins/cycle
\end{equation*}

\section{Cache Behavior (2pts each)}
\subsection{Q1}
This oddity could be seen if the program was executing in a loop and the number in instructions was twice the size of the cache.  In this case, the least-recently-used scheme would keep removing instructions from the cache before they were needed.  However in the direct mapped cache, it's possible for some of the instructions to remain in the cache, and provide at least some cache hits.

\subsection{Q2}
\subsubsection{A}
Any data that enters the cache, but is never used, is essentially wasted.  Caching only helps for instructions that are prefetched, or used repeatedly.  

\subsubsection{B}
You would need to know wether or not the memory will be used before it is flushed.  While this seems like an unreasonable assumption, some educated guesses could be made (e.g., if there is never a  load from a data memory region).

\section{Transactional Memory (3pts each)}



\end{document}